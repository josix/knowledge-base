---
title: "Agent Design Patterns and MoE Architecture Insights"
date: 2026-02-05T10:00:00
dg-publish: true
dg-permalink: random-thoughts/2025-02-05
description: "Notes on AI agent design patterns discovered while building agent-flow, and their connection to Mixture of Experts architecture"
tags:
  - ai-agent
  - moe
  - llm
  - architecture
  - random-thoughts
---

> 沒什麼組織、一些倏忽即逝有趣或不有趣的想法

- Agent Design Patterns from building [agent-flow](https://github.com/josix/agent-flow)

## 1. Layered Prompt Design

The key insight: prompts should have clear hierarchy and priority.

```
Command Prompt (highest priority - what user wants NOW)
    └── Agent Prompt (role definition, behavior guidelines)
        └── Skills Prompt (domain knowledge, loaded on-demand)
            └── Hooks (runtime context injection)
```

**Why layering matters:**
- Single monolithic prompts create priority confusion
- When instructions conflict, agent doesn't know what to prioritize
- Different layers have different update frequencies and maintenance needs

**Behavior guidelines > strict constraints:**
- Instead of "DO NOT install packages without permission"
- Write: "When a tool isn't available, first look for alternatives using existing tools"
- Gives model a decision framework, not just prohibitions
- The polib example: Agent found GNU gettext CLI tools when polib wasn't installed, because it was guided to "find alternatives" rather than "report failure"

## 2. Memory Management - Episodic Memory Analogy

Agent memory works like human episodic memory:
- Selective: not everything is stored
- Mutable: memories change over time
- Externalizable: can use memos/notes

Three-layer architecture:
- **Short-term**: current conversation context (bounded by context window)
- **Working memory**: current task state (what files are being modified, what's been tried)
- **Long-term**: persistent knowledge via memo system

Checkpoint mechanism for long-running tasks - save progress, restore on failure.

## 3. Generalist + Specialist Model

**Generalists** (Agents):
- Explorer: understand problem space
- Planner: break down tasks
- Reviewer: audit results
- Verifier: ensure correctness

**Specialists** (Skills):
- Python, Frontend, Database, DevOps skills
- Loaded on-demand via Skill Manager
- Unloaded when not needed to save context

This is like a software team:
- Tech lead (generalist) coordinates and plans
- Domain experts (specialists) execute in their areas

## 4. Divergent vs Convergent Tasks

**Divergent tasks** - no correct answer:
- Exploring problem space
- Designing solutions
- Planning approaches
- Strategy: give freedom, higher temperature, don't over-constrain

**Convergent tasks** - has correct answer/success criteria:
- Fixing specific bugs
- Implementing to spec
- Passing tests
- Strategy: strict verification, iterate until correct, lower temperature

**Mistake to avoid:**
- Treating divergent as convergent → over-conservative, kills creativity
- Treating convergent as divergent → produces plausible but buggy code

## 5. Connection to MoE Architecture

The patterns map surprisingly well to Mixture of Experts:

| MoE Concept | Agent Design |
|-------------|--------------|
| Router/Gate | Planner Agent (decides who handles what) |
| Experts | Skills (specialized knowledge modules) |
| Sparse Activation | On-demand loading (only activate what's needed) |
| Expert Combination | Multi-skill collaboration |

**Why this matters:**
1. **Specialization works** - different experts for different inputs beats one generalist
2. **Sparse activation is efficient** - don't load all skills for every task
3. **Routing is critical** - Planner quality determines system ceiling

The similarity isn't coincidence - both MoE and good agent design are modeling how effective human teams work:
- Someone decides who does what (router/tech lead)
- Specialists focus on their domains (experts/domain engineers)
- Not everyone works on every task (sparse activation)

## Meta observation

Good agent design comes from understanding the problem deeply, not from using cool tech. These patterns emerged from solving real problems:
- How do we prioritize conflicting instructions? → Layered prompts
- How do we handle multi-step tasks? → Memory + checkpoints
- How do we balance breadth and depth? → Generalist + Specialist
- How do we handle different task types? → Divergent/Convergent distinction

The MoE connection is a nice validation - when your heuristic design matches what works at the neural network level, you're probably onto something real.

---

References:
- [agent-flow](https://github.com/josix/agent-flow)
- [Mixture of Experts Explained - Hugging Face](https://huggingface.co/blog/moe)
- [Switch Transformers paper](https://arxiv.org/abs/2101.03961)
- [Building LLM applications for production - Chip Huyen](https://huyenchip.com/2023/04/11/llm-engineering.html)
