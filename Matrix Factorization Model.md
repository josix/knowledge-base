---
tags: recsys, thesis
---

# Matrix Factorization Model

Matrix Factorization Model 又稱為矩陣分解法，為[[推薦系統]]中[[協同過濾]]策略的經典算法之一，其主要想法是基於使用者和商品的互動評分向量化使用者和商品的潛在因素，越高的評分代表該商品應該被推薦。模型可以由矩陣作為呈現，矩陣的ㄧ列代表一個使用者，矩陣的ㄧ行代表一個商品，矩陣的元素代表該使用者和商品的互動評分。模型的資料來源有兩種，一種為品質較好的明確回饋（explicit feedback），包含使用者明確給出針對商品的評分，像是 YouTube 的按讚機制、Google Map 商家的評分機制等，此種資料雖然明確卻不容易取得，數量也會遠小於使用者和商品的數量，因此容易形成稀疏矩陣（sparse matrix），另一種資料為隱性回饋（implicit feedback），為間接可以代表使用者喜好的使用者行為包含使用者購買紀錄、瀏覽紀錄、搜尋紀錄等，通常會以這些行為存在與否作為紀錄，容易形成密集矩陣（dense matrix）。

Matrix Factorization Model 會將使用者和商品映射到一個共同的向量空間並有著相同的維度，並將向量間的內積用於模擬使用者和商品間互動評分。其定義每一個商品 $i$ 對應著向量 $q_i ∈ \mathbb{R^f}$，向量每個維度意味著商品所擁有的潛在因素（Latent Factor）是多或少（在向量空間中是正或負），每一個使用者 $u$ 對應著向量 $p_u ∈ \mathbb{R^f}$，其中的每個維度意味著使用者基於每個潛在因素對於商品的喜好程度高或低，而使用者 $u$ 和商品 $i$ 的互動評分 $r_{ui}$ 即 $q_i$ 和 $p_u$ 的內積 $q_i^T p_u$，意味著使用者對於商品各項因素的總體喜好程度。模型的最大挑戰在於求得使用者和商品的向量，計算出所有的向量，即可以推測出使用者和商品的互動評分基於此公式 $\hat{r_{ui}} = q_i^Tp_u$。

此種將矩陣拆解為使用者矩陣和商品矩陣的作法類似 [[奇異值分解]]（singular value decomposition），但由於 SVD 並不能有效針對稀疏矩陣進行分解，而替代的代入法（Imputation）如代入平均值等會導致增加相當大量的資料，並且不容易確保可信度。因此 Matrix Factorization 的做法是直接針對互動評分進行建模，並且透過[[正則化]]（regularization）來避免過擬合。最終的模型公式如下：

$$
\mathcal{L} = min_{q^*, p^*} \sum_{i, u ∈ \kappa} (r_{ui} - q_i^T p_u)^2 + \lambda \sum_{i} (q_i^T q_i) + \lambda \sum_{u} (p_u^T p_u)
$$

其中 $\kappa$ 是使用者和商品的互動評分資料集，$\lambda$ 是正則化參數，$q_i$ 和 $p_u$ 是使用者和商品的向量，$q_i^T p_u$ 是使用者和商品的互動評分。學習時會以過去的互動評分為目標，因此需要透過正則化對向量中過大的值進行扣分來避免過擬合。

## 學習演算法

